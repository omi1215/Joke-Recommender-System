{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJRF1-U6BmX7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-aj0Vy8t0DF",
        "outputId": "9594d90d-58ea-458e-a366-d860788985bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LAnqDULugjS",
        "outputId": "fe721fec-99ef-4590-feca-a235ca5389dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6FlOrxL7ttIB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from surprise import Dataset, Reader, KNNBasic, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "import gc\n",
        "\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/FINAL jester 2006-15.xls', header=None)\n",
        "\n",
        "\n",
        "df = df.drop(columns=[0])\n",
        "\n",
        "\n",
        "df.insert(loc=0, column=\"User ID\", value=np.arange(1, len(df.index) + 1))\n",
        "\n",
        "\n",
        "removed_jokes = {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 20, 27, 31, 43, 51, 52, 61, 73, 80, 100, 116}\n",
        "df = df.drop(columns=[col for col in removed_jokes], axis=1)\n",
        "\n",
        "# Reshape the data (convert wide format to long format)\n",
        "df = df.melt(id_vars=\"User ID\", var_name=\"Joke ID\", value_name=\"Rating\")\n",
        "\n",
        "# Remove null ratings (99 corresponds to null ratings)\n",
        "df = df[df[\"Rating\"] != 99]\n",
        "\n",
        "# Ensure data is sorted by User ID and Joke ID\n",
        "df = df.sort_values(by=[\"User ID\", \"Joke ID\"]).reset_index(drop=True)\n",
        "\n",
        "# Step 2: use only users with at least 10 ratings\n",
        "user_ratings_count = df.groupby('User ID').size()\n",
        "users_with_enough_ratings = user_ratings_count[user_ratings_count >= 10].index\n",
        "df = df[df['User ID'].isin(users_with_enough_ratings)]\n",
        "\n",
        "# using only 5000 users and 50 jokes\n",
        "df = df[df['User ID'] <= 5000]\n",
        "df = df[df['Joke ID'] <= 75]\n",
        "\n",
        "# Remove users and jokes with no ratings\n",
        "df = df[df.groupby('User ID')['Rating'].transform('count') > 0]\n",
        "df = df[df.groupby('Joke ID')['Rating'].transform('count') > 0]\n",
        "\n",
        "# Normalize ratings (subtract user mean)\n",
        "df['Normalized Rating'] = df.groupby('User ID')['Rating'].transform(lambda x: x - x.mean())\n",
        "\n",
        "\n",
        "#  Re-scaling after normalization\n",
        "min_rating = df['Normalized Rating'].min()\n",
        "max_rating = df['Normalized Rating'].max()\n",
        "\n",
        "df['Rescaled Normalized Rating'] = (df['Normalized Rating'] - min_rating) / (max_rating - min_rating) * (10 - (-10)) - 10\n",
        "\n",
        "# Step 3: Load data into Surprise's format\n",
        "reader = Reader(rating_scale=(-10, 10))\n",
        "data = Dataset.load_from_df(df[['User ID', 'Joke ID', 'Normalized Rating']], reader)\n",
        "\n",
        "# Step 4: Train-test split\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P95ykytuYsZ",
        "outputId": "488687ed-6c70-4b93-cd11-0274b53186f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal K: 25, Shrinkage: 50, Best MAE: 3.4080\n"
          ]
        }
      ],
      "source": [
        "from surprise import KNNBasic, accuracy\n",
        "from surprise.model_selection import cross_validate\n",
        "from joblib import Parallel, delayed\n",
        "import numpy as np\n",
        "\n",
        "best_mae = float('inf')\n",
        "\n",
        "# Parallelized hyperparameter search\n",
        "def train_and_evaluate(k, shrink):\n",
        "    sim_options = {\n",
        "        'name': 'pearson_baseline',\n",
        "        'user_based': True,\n",
        "        'shrinkage': shrink\n",
        "    }\n",
        "    algo = KNNBasic(k=k, sim_options=sim_options, min_k=5)\n",
        "    algo.fit(trainset)\n",
        "    predictions = algo.test(testset)\n",
        "    mae = accuracy.mae(predictions, verbose=False)\n",
        "    return (k, shrink, mae)\n",
        "\n",
        "results = Parallel(n_jobs=4)(delayed(train_and_evaluate)(k, shrink) for k in range(5, 30, 5) for shrink in [50, 100, 150, 200])\n",
        "\n",
        "# Find the best result\n",
        "best_result = min(results, key=lambda x: x[2])\n",
        "optimal_k, optimal_shrinkage, best_mae = best_result\n",
        "print(f\"Optimal K: {optimal_k}, Shrinkage: {optimal_shrinkage}, Best MAE: {best_mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVM1UryJ-TSu",
        "outputId": "1acb14c6-ac81-4395-b3af-5af4630594c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User Bias Model MAE: 3.828883073271953\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def user_bias_recommender(trainset, testset):\n",
        "    # Calculate the mean rating for each user\n",
        "    user_ratings = defaultdict(list)\n",
        "    for uid, iid, rating in trainset.all_ratings():\n",
        "        user_ratings[uid].append(rating)\n",
        "\n",
        "    user_means = {uid: np.mean(ratings) for uid, ratings in user_ratings.items()}\n",
        "\n",
        "    # Predict the mean rating for each user in the test set\n",
        "    base_predictions = []\n",
        "    for uid, iid, true_r in testset:\n",
        "        predicted_rating = user_means.get(uid, np.mean([rating for (_, _, rating) in trainset.all_ratings()]))  # Fallback to global mean if no user data\n",
        "        base_predictions.append((uid, iid, predicted_rating, true_r))\n",
        "\n",
        "    return base_predictions\n",
        "\n",
        "# Generate baseline predictions and calculate MAE\n",
        "base_preds = user_bias_recommender(trainset, testset)\n",
        "base_mae = np.mean([abs(true_r - est) for (_, _, est, true_r) in base_preds])\n",
        "print(f\"User Bias Model MAE: {base_mae}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iszaFY3NNPbz",
        "outputId": "2051a383-0e20-4066-f812-73c6920c1c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Data Instances with Predictions:\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "User: 3067, Joke: 74, True Rating: -1.34, Predicted Rating: -2.03\n",
            "User: 3554, Joke: 26, True Rating: -8.33, Predicted Rating: -1.59\n",
            "User: 2008, Joke: 41, True Rating: -5.85, Predicted Rating: -2.38\n",
            "User: 1963, Joke: 53, True Rating: 4.43, Predicted Rating: 2.98\n",
            "User: 822, Joke: 8, True Rating: -5.34, Predicted Rating: -1.03\n",
            "User: 1876, Joke: 67, True Rating: 3.73, Predicted Rating: -1.28\n",
            "User: 3246, Joke: 70, True Rating: -1.47, Predicted Rating: 1.43\n",
            "User: 1827, Joke: 23, True Rating: -5.85, Predicted Rating: -1.03\n",
            "User: 2248, Joke: 26, True Rating: 3.82, Predicted Rating: -0.41\n",
            "User: 2196, Joke: 72, True Rating: 7.88, Predicted Rating: 2.25\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Show test instances with predictions\n",
        "print(\"\\nTest Data Instances with Predictions:\")\n",
        "\n",
        "# Use the trained model to make predictions on the test set\n",
        "algo = KNNBasic(k=optimal_k, sim_options={'name': 'pearson_baseline', 'user_based': True, 'shrinkage': optimal_shrinkage}, min_k=5)\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Display test instances with original and predicted ratings\n",
        "for i, prediction in enumerate(predictions[:10]):\n",
        "    uid = prediction.uid\n",
        "    iid = prediction.iid\n",
        "    true_r = prediction.r_ui\n",
        "    est = prediction.est\n",
        "    print(f\"User: {uid}, Joke: {iid}, True Rating: {true_r:.2f}, Predicted Rating: {est:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNIjv0k9-YOY",
        "outputId": "6cd121ab-f1af-47fc-8c4b-33b5d81487d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 2000 Similar Users for User 1 with Similarity Measures:\n",
            "Neighbor User: 1, Similarity: 1.0000\n",
            "Neighbor User: 1024, Similarity: 0.1892\n",
            "Neighbor User: 1284, Similarity: 0.1835\n",
            "Neighbor User: 100, Similarity: 0.1776\n",
            "Neighbor User: 3289, Similarity: 0.1710\n",
            "Neighbor User: 471, Similarity: 0.1608\n",
            "Neighbor User: 4967, Similarity: 0.1597\n",
            "Neighbor User: 326, Similarity: 0.1571\n",
            "Neighbor User: 3413, Similarity: 0.1569\n",
            "Neighbor User: 836, Similarity: 0.1489\n",
            "\n",
            "Predicted Ratings for User 1:\n",
            "Joke ID: 28, Predicted Rating: 0.98\n",
            "Joke ID: 30, Predicted Rating: -0.84\n",
            "Joke ID: 48, Predicted Rating: 1.27\n",
            "Joke ID: 33, Predicted Rating: -2.14\n",
            "Joke ID: 37, Predicted Rating: -1.10\n",
            "Joke ID: 38, Predicted Rating: 0.69\n",
            "Joke ID: 39, Predicted Rating: 0.96\n",
            "Joke ID: 40, Predicted Rating: -0.02\n",
            "Joke ID: 41, Predicted Rating: -0.64\n",
            "Joke ID: 44, Predicted Rating: -3.29\n",
            "Joke ID: 45, Predicted Rating: 0.76\n",
            "Joke ID: 46, Predicted Rating: 0.61\n",
            "Joke ID: 47, Predicted Rating: 2.27\n",
            "Joke ID: 55, Predicted Rating: -0.38\n",
            "Joke ID: 56, Predicted Rating: 1.80\n",
            "Joke ID: 59, Predicted Rating: -0.37\n",
            "Joke ID: 60, Predicted Rating: -1.34\n",
            "Joke ID: 63, Predicted Rating: 1.27\n",
            "Joke ID: 70, Predicted Rating: 0.86\n",
            "Joke ID: 57, Predicted Rating: -2.91\n",
            "Joke ID: 58, Predicted Rating: -3.59\n",
            "Joke ID: 64, Predicted Rating: -0.92\n",
            "Joke ID: 67, Predicted Rating: -1.38\n",
            "Joke ID: 71, Predicted Rating: -1.59\n",
            "Joke ID: 74, Predicted Rating: -2.24\n",
            "Joke ID: 75, Predicted Rating: -1.23\n"
          ]
        }
      ],
      "source": [
        "def inference_for_user_with_sim_and_predictions(target_user_id, top_k_users=2000):\n",
        "\n",
        "    target_inner_id = algo.trainset.to_inner_uid(target_user_id)\n",
        "\n",
        "    # Step 2: Get the similarity matrix from the trained model\n",
        "    sim_matrix = algo.sim\n",
        "\n",
        "    # Get the similarity scores for the target user with all other users\n",
        "    similarities = sim_matrix[target_inner_id]\n",
        "\n",
        "    # Sort users by similarity \n",
        "    similar_users = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the top K similar users\n",
        "    top_users_sim = [(algo.trainset.to_raw_uid(inner_id), sim) for inner_id, sim in similar_users[:top_k_users]]\n",
        "\n",
        "    # Step 3: Print the top K similar users and their similarity scores\n",
        "    print(f\"\\nTop {top_k_users} Similar Users for User {target_user_id} with Similarity Measures:\")\n",
        "    for neighbor_id, similarity in top_users_sim[:10]:\n",
        "        print(f\"Neighbor User: {neighbor_id}, Similarity: {similarity:.4f}\")\n",
        "\n",
        "    unrated_jokes = df[~df['Joke ID'].isin(df[df['User ID'] == target_user_id]['Joke ID'])]['Joke ID'].unique()\n",
        "\n",
        "    predicted_ratings = {}\n",
        "    for joke_id in unrated_jokes:\n",
        "        # Use the trained model to predict the rating for this joke\n",
        "        prediction = algo.predict(target_user_id, joke_id)\n",
        "        predicted_ratings[joke_id] = prediction.est  # predicted rating\n",
        "\n",
        "    # Step 5: Print the predicted ratings for the target user\n",
        "    print(f\"\\nPredicted Ratings for User {target_user_id} based on the trained model:\")\n",
        "    for joke_id, rating in predicted_ratings.items():\n",
        "        print(f\"Joke ID: {joke_id}, Predicted Rating: {rating:.2f}\")\n",
        "\n",
        "    return predicted_ratings, top_users_sim\n",
        "\n",
        "# Example: Predict for a specific user\n",
        "target_user_id = 1\n",
        "predicted_ratings, top_users = inference_for_user_with_sim_and_predictions(target_user_id=target_user_id)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
